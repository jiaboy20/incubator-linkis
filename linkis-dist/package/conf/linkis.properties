# 
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
# http://www.apache.org/licenses/LICENSE-2.0
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

##enable wds.linkis.test.mode where use knife4j
wds.linkis.test.mode=false
wds.linkis.test.user=root
wds.linkis.server.version=v1
linkis.discovery.prefer-ip-address=false
linkis.discovery.server-address=http://bigd-sit-linkis-mgr1:8761

##spring conf
wds.linkis.gateway.url=http://bigd-sit-linkis-mgr1:9111

##mybatis
wds.linkis.server.mybatis.datasource.url=jdbc:mysql://10.110.7.18:32111/linkisdb?characterEncoding=UTF-8
wds.linkis.server.mybatis.datasource.username=linkis
wds.linkis.server.mybatis.datasource.password=linkis@1234
# mysql
wds.linkis.mysql.is.encrypt=false
linkis.mysql.strong.security.enable=false
linkis.mysql.force.params=allowLoadLocalInfile=false&autoDeserialize=false&allowLocalInfile=false&allowUrlInLocalInfile=false
linkis.mysql.sensitive.params=allowLoadLocalInfile,autoDeserialize,allowLocalInfile,allowUrlInLocalInfile,#

#hadoop/hive/spark config
hadoop.config.dir=/etc/hadoop/conf
hive.config.dir=/etc/hive/conf
spark.config.dir=/etc/spark/conf
flink.version=1.12.7

#wds.linkis.keytab.enable=true
#wds.linkis.keytab.file=/appcom/keytab/


##file path
wds.linkis.filesystem.root.path=file:///home/nfs/workspace
wds.linkis.filesystem.hdfs.root.path=hdfs:///linkis/workspace
wds.linkis.udf.share.path=hdfs:///linkis/udf/
##bml path:default use hdfs
wds.linkis.bml.is.hdfs=true
wds.linkis.bml.hdfs.prefix=/linkis/bml
wds.linkis.bml.local.prefix=/home/nfs/bml

##engine Version
wds.linkis.spark.engine.version=2.4.0
wds.linkis.hive.engine.version=2.1.1
#wds.linkis.python.engine.version=
wds.linkis.flink.engine.version=1.12.7

#LinkisHome
wds.linkis.home=/opt/linkis
#Linkis governance station administrators
wds.linkis.governance.station.admin=root,jiangkun0928

#linkis jobhistory admin can get all job list
wds.linkis.jobhistory.admin=root

#wds.linkis.gateway.conf.publicservice.list=query,jobhistory,application,configuration,filesystem,udf,variable,microservice,errorcode,bml,datasource

wds.linkis.prometheus.enable=true
wds.linkis.server.user.restful.uri.pass.auth=/api/rest_j/v1/actuator/prometheus,/api/rest_j/v1/offline,/api/rest_j/v1/doc.html,/api/rest_j/v1/swagger-resources,/api/rest_j/v1/webjars,/api/rest_j/v1/v2/api-docs

wds.linkis.gateway.conf.metadataquery.list=metadatamanager,metadataquery

# note: org.springframework.cloud.config.client.ConfigServiceBootstrapConfiguration.configServicePropertySource need to disable
spring.spring.cloud.config.enabled=false

# linkis user ticket sso
# redis stand-alone
linkis.session.redis.host=10.110.7.18
linkis.session.redis.port=30290
### redis sentinel model config sentinel-master-name
#linkis.session.redis.sentinel.master=
#### 192.168.1.1:6381,192.168.2.1:6381,192.168.3.1:6381
#linkis.session.redis.sentinel.nodes=
# redis password
linkis.session.redis.password=linkis@1234
# redis sso switch
linkis.session.redis.cache.enabled=true
